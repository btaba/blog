---
layout: post
title:  "yarlp"
date:   2017-08-23 00:00:00
categories: projects
tags: projects
comments: True
---

There are a lot of packages out there for deep Reinforcement Learning (RL), and so it became obvious to me that there needed to be yet another implementation! I'm calling it [**`yarlp`**](http://github.com/btaba/yarlp), Yet Another Reinforcement Learning Package! I'm developing it mostly for educational purposes.

Here are several great implementations that I've learned and borrowed from:

1. [rllab](https://github.com/openai/rllab)
2. [baselines](https://github.com/openai/baselines)
3. [mindpark](https://github.com/danijar/mindpark)

[**`yarlp`**](http://github.com/btaba/yarlp) heavily uses `tensorflow==1.3` and `gym`, and is meant to be simple to run, yet very configurable. Here is an example running TRPO:

{% highlight python %}
from yarlp.agent.trpo_agent import TRPOAgent
from yarlp.utils.env_utils import NormalizedGymEnv
from yarlp.model.networks import mlp

env = NormalizedGymEnv(
    'MountainCarContinuous-v0',
    normalize_obs=True)

agent = TRPOAgent(
    env, discount_factor=0.99,
    policy_network=mlp)

agent.train(100, 0, n_steps=1024)
{% endhighlight %}

I'm planning to benchmark TRPO on several environments and then move over to value-based methods.


Here are tons of other RL packages:

- [tensorforce](https://github.com/reinforceio/tensorforce)
- [universe-starter-agent](https://github.com/openai/universe-starter-agent)
- [imitation](https://github.com/openai/imitation)
- [modular_rl](https://github.com/joschu/modular_rl/tree/master/modular_rl)
- [keras-rl](https://github.com/matthiasplappert/keras-rl)
- [reinforcement-learning](https://github.com/dennybritz/reinforcement-learning)
- [python-rl](https://github.com/amarack/python-rl)
- [rlpark](https://github.com/rlpark/rlpark)
- [AgentNet](https://github.com/yandexdataschool/AgentNet)
- [openai_lab](https://github.com/kengz/openai_lab)
- [deep-rl-tensorflow](https://github.com/carpedm20/deep-rl-tensorflow)
- drop a comment to add more to the list!
